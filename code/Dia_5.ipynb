{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67fa111b-d392-4779-a7ed-64a2fd0c2cd7",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/ulises1229/Intro-ML-Python/blob/master/code/Dia_5.ipynb\\\" target=\"_parent\\\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\\\" alt=\"Open In Colab\\\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10af191-9600-4fbb-9b74-888705cc2b06",
   "metadata": {},
   "source": [
    "# Día 5: Aprendizaje profundo (Deep Learning)\n",
    "<ul>\n",
    "    <li><strong>Autor:</strong> Walter Rosales</li>\n",
    "    <li><strong>Contacto:</strong> <a href=\"mailto:walt22r@outlook.com\">walt22r@outlook.com</a>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600233bc-d20c-41c5-b7ff-828ac09633a5",
   "metadata": {},
   "source": [
    "---\n",
    "#### Deep Learning, Machine Learning e Inteligencia Artificial ¿son lo mismo?\n",
    "\n",
    "> <img src=\"../figs/nvidia-ai-comparison.png\" width=700/>\n",
    ">\n",
    "> Fig 1. Linea temporal del surgimiento de Inteligencia Artificial, Machine Learning y Deep Learning. \n",
    "> \n",
    "> Fuente: <a href=\"https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/\">Blog de NVIDIA</a>\n",
    "\n",
    "Como se puede apreciar en la Fig. 1, en realidad una es un subconjunto de la otra. En particular Deep Learning es un subconjunto de Machine Learning, que a su vez lo es de algo mucho más grande que se denomina Inteligencia Artificial. Puedes encontrar más información también en [este artículo de IBM](https://www.ibm.com/cloud/blog/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks).\n",
    "\n",
    "Existe una particularidad que define a los algoritmos de Deep Learning dentro de los de Machine Learning, y es su capacidad de aprender sin necesidad de una intervención/decisión humana directo respecto al modelo (ver Fig. 2).\n",
    "\n",
    "> <img src=\"../figs/ML_vs_DL.png\" width=700/>\n",
    ">\n",
    "> Fig. 2. Comparación entre algoritmos de Machine Learning y Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a8e9ab-aac0-40d1-bc2e-a7c8058ad6cd",
   "metadata": {},
   "source": [
    "---\n",
    "## Deep Learning\n",
    "\n",
    "Conjunto de algoritmos que utilizan una estrategia de capas ocultas (_hidden layers_) con funciones de activación no lineales internas entre una capa de entrada y una de salida. Es decir, modelos bioinspirados por el funcionamiento general del cerebro biológico, como se establece de forma general en [este otro artículo de IBM](https://www.ibm.com/cloud/learn/deep-learning).\n",
    "\n",
    "> <img src=\"../figs/bioinspired_DL_neuron.png\" width=440>\n",
    "> \n",
    "> Fig. 3: a) Esquema de una neurona del sistema nervioso biológico. b) Representación matemática/computacional de una neurona artificial.\n",
    "> \n",
    "> Fuente: [Zhu, G., Jiang, B., Tong, L., Xie, Y., Zaharchuk, G., &amp; Wintermark, M. (2019). Applications of deep learning to neuro-imaging techniques. Frontiers in Neurology, 10. https://doi.org/10.3389/fneur.2019.00869 ](https://www.frontiersin.org/articles/10.3389/fneur.2019.00869/full)\n",
    "\n",
    "En la Fig. 3 podemos observar cómo se plantea la similitud entre una neurona biolígica, y se respectivo modelo matemático que se utiliza para emular su respuesta ante estímulos y que sirve como base para construir redes neuronales artificiales como es mostrado en la Fig. 4.\n",
    "\n",
    "> <img src=\"../figs/bioinspired_DL_network.jpg\" width=600>\n",
    "> \n",
    "> Fig. 4: Emulación de una red neuronal artificial (B) y su representación análoga en el sistema nervioso biológico (A) para clasificar a partir de datos gráficos (imagen) como entrada.\n",
    ">\n",
    "> Fuente: [Mohamed K.S. (2020) Deep Learning and Cognitive Computing: Pillars and Ladders. In: Neuromorphic Computing and Beyond. Springer, Cham. https://doi.org/10.1007/978-3-030-37224-8_4](https://link.springer.com/chapter/10.1007/978-3-030-37224-8_4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4168a113-4055-4b88-af01-b8a633980cf2",
   "metadata": {},
   "source": [
    "### Modelos de Deep Learning\n",
    "\n",
    "Existen diversos modelos de Deep Learning, cada día habiendo más y más, siendo los más comúnes los feed-forward neural network (también conocidos como ANN de Artificial Neural Network), Convolutional Neural Networks (CNN), Recurrent Neural Network (RNN) y muchas más (ver Fig. 5). Y sus actuales aplicaciones son el mejor referente de su éxito, algunos de los más importantes están mencionados en [Wikipedia](https://en.wikipedia.org/wiki/Deep_learning#Applications).\n",
    "\n",
    "> <img src=\"../figs/DL_architectures.png\" width=500 />\n",
    "> \n",
    "> Fig. 5: Diagramas de las diferentes arquitecturas de redes neuronales más comúnes en la literatura actual. \n",
    ">\n",
    "> Fuente: [Kwon, S.H.; Kim, J.H. (2021) Machine Learning and Urban Drainage Systems: State-of-the-Art Review. Water, 13. https://doi.org/10.3390/w13243545](https://www.mdpi.com/2073-4441/13/24/3545)\n",
    "\n",
    "Siguiendo todos estos un patrón esencial, cuentan con tres componentes básicos: una capa de entrada, una o varias capas ocultas y una capa de salida (ver Fig. 6), siendo la primera donde ingresan los datos, las siguientes donde se procesa y se _aprende_ y la última aquella que da la _predicción_ del modelo.\n",
    "\n",
    "> <img src=\"../figs/ANN_architecture.png\" width=600 />\n",
    ">\n",
    "> Fig. 6: Esquema general de un modelo de red neuronal artificial (ANN) ejemplificando los tres tipos de capas que la componen: entrada ($i$), ocultas ($h_n$) y salida ($o$).\n",
    ">\n",
    "> Fuente: [Bre, F., Gimenez, J. M., &amp; Fachinotti, V. D. (2018). Prediction of wind pressure coefficients on building surfaces using artificial neural networks. Energy and Buildings, 158, 1429–1441. https://doi.org/10.1016/j.enbuild.2017.11.045](https://www.sciencedirect.com/science/article/abs/pii/S0378778817325501?via%3Dihub)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2d7a7a-2a07-4e6c-b0ee-9525c38159a7",
   "metadata": {},
   "source": [
    "### Requerimientos para crear un modelo de DL\n",
    "\n",
    "Para crear un modelo de DL es necesario contar con los siguientes cuatro pilares básicos:\n",
    "1. Datos\n",
    "2. Arquitectura\n",
    "3. Función de pérdida\n",
    "4. Optimizador\n",
    "\n",
    "#### Datos\n",
    "Al ser los algoritmos de DL pertenecientes a la categoría de Aprendizaje Supervisado, es necesario que todos los datos estén _etiquetados_ con su correspondiente _respuesta correcta_ o _esperada_ la cual se utilizará para evaluar el rendimiento del modelo. El tipo de datos que se puede utilizar es altamente variado, desde imágenes, texto plano, vídeos hasta simples valores numéricos; la limitante es que puedan se representados de forma numérica para ingresarlos a las capas de entrada.\n",
    "\n",
    "#### Arquitectura\n",
    "Es necesario definir qué estructura (estática) se desea utilizar (i.e. CNN, RNN, ANN, etc.), así como la estructura (número de capas ocultas, neuronas en cada una, funciones de activación, etc.). Recuerda que hay diversas redes _ideales_ para cierto tipo de datos de entrada, pero no te limites, **deja salir tu creatividad**.\n",
    "\n",
    "#### Función de pérdida\n",
    "Es la forma de evaluar si el modelo está haciendo las cosas bien o no, nuevamente dependerá de tu caso, pero las más comúnes son:\n",
    "\n",
    "**Regresión**\n",
    "- Mean Absolute Error (error absoluto promedio) $MAE = \\frac{1}{n}\\sum_{i=1}^{n}|{Y_i - \\hat{Y}_i}|$\n",
    "- Mean Squared Error (error cuadrático medio) $MSE = \\frac{1}{n}\\sum_{i=1}^{n}(Y_i - \\hat{Y}_i)^2$\n",
    "\n",
    "**Clasificación**\n",
    "- Binary Cross Entropy (clasificación binaria) $H_p(q) = -\\frac{1}{n}\\sum_{i=1}^{n}Y_i \\dot log(p(Y_i)) + (1 - Y_i) \\dot log(1 - p(Y_i))$ donde $p(Y_i) = \\hat{Y}_i$, puedes indagar un poco más [aquí](https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a)\n",
    "- Categorical Cross Entropy (clasificación de múltiples categorías)\n",
    "\n",
    "#### Optimizador\n",
    "Para poder actualizar los parámetros de cada capa es necsario definir un algoritmo para hacerlo, ese es el optimizador, es decir, qué regla (fórmula matemática) vamos a seguir para actualizarlo. Esto está relacionado con el proceso de _backpropagation_ que es la clave para actualizar los valores dependiendo de la pérdida (error) que hubo entre $Y_i$ y $\\hat{Y}_i$ (también denotada como $Y^*$ (ver Fig. 7) ¨**pero no te espantes, no debes de comprender todas las operaciones matemáticas, tan solo conocer cómo es el proceso**.\n",
    "\n",
    "> <img src=\"../figs/backpropagation.png\" width=600 />\n",
    ">\n",
    "> Fig. 7: Diagrama y algoritmo de backpropagation, así como regla de actualización de parámetros (optmimización) como se ilustra en la sección (b) en el punto (ii).\n",
    ">\n",
    "> Fuente: [Backpropagation, Medium](https://medium.com/@jorgesleonel/backpropagation-cc81e9c772fd)\n",
    "\n",
    "Algunos de los algoritmos más usados son:\n",
    "- Stochastic Gradient Descent (SGD)\n",
    "- ADAM\n",
    "\n",
    "Puedes encontrar información sobre estos y muchos otros en [este artículo en Medium](https://medium.com/mlearning-ai/optimizers-in-deep-learning-7bf81fed78a0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c089e3-c07a-4c79-85a1-51cf4a0520c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
